# Alzheimers Framework: User Manual

This manual provides a step-by-step guide to operating the *Alzheimers* framework, from environment setup and data generation to model training and live implant execution.

---

## 1. Environment Setup

### Prerequisites
-   **OS**: Windows 10/11 (Required for Artifact Fabrication)
-   **Python**: 3.10+
-   **Privileges**: Administrator access is required for Event Log injection and DNS cache manipulation.

### Installation

1.  **Clone the Repository**:
    ```bash
    git clone <repository_url>
    cd DF_PROJECT
    ```

2.  **Install Dependencies**:
    ```bash
    pip install -r requirements.txt
    ```
    *Note: If you encounter issues with `scapy` on Windows, ensure Npcap is installed.*

---

## 2. Data Generation

The framework relies on two distinct datasets: **Synthetic Host Logs** (for gadget chains) and **Network Artifacts** (for background noise).

### A. Generate Synthetic Host Data
This script generates a labeled dataset of process execution chains based on defined personas (Developer, Office Worker).

```bash
python scripts/generate_synthetic_dataset.py --num-events 50000 --output data/processed/local_train.parquet
```
-   `--num-events`: Number of events to generate (Recommended: 50,000+).
-   `--output`: Path to save the Parquet file.

### B. Generate Network Artifact Data
This script generates network traffic logs and browser history artifacts.

```bash
python scripts/generate_host_network_dataset.py --num-records 20000 --output data/processed/host_network_train.parquet
```
-   `--num-records`: Number of network records to generate.

---

## 3. Preprocessing & Tokenization

Before training, raw data must be tokenized.

### A. Train Tokenizers
Train separate tokenizers for host and network data to handle their distinct vocabularies.

```bash
# Train Host Tokenizer
python scripts/train_tokenizer_synthetic.py --input data/processed/local_train.parquet --output data/processed/tokenizer_synthetic

# Train Network Tokenizer
python scripts/train_tokenizer_host.py --input data/processed/host_network_train.parquet --output data/processed/tokenizer_host
```

---

## 4. Model Training

The framework uses a **Dual-Model** architecture. You must train both models.

### A. Train General Host Model (Gadget Chains)
This model learns to generate complex process trees (e.g., `code.exe` -> `python.exe`).

```bash
python scripts/train_model.py --config configs/model_config.yaml --dataset-file local_train.parquet --tokenizer-dir tokenizer_synthetic --epochs 5 --checkpoint-dir checkpoints/host_model
```
-   `--dataset-file`: Name of the file in `data/processed`.
-   `--tokenizer-dir`: Directory name of the tokenizer in `data/processed`.
-   `--checkpoint-dir`: Where to save the model weights.

### B. Train Host Network Model (Background Noise)
This model learns to generate realistic network traffic and browser history.

```bash
python scripts/train_network_gan.py --config configs/model_config.yaml --dataset-file host_network_train.parquet --tokenizer-dir tokenizer_host --epochs 3 --checkpoint-dir checkpoints/network_model
```

---

## 5. Live Execution (The Implant)

Once trained, the `unified_implant.py` script loads both models and executes the "Smoke Bomb" evasion strategy.

### Basic Execution
```bash
python scripts/unified_implant.py
```

### Advanced Modes

1.  **Discrete Mode (Recommended)**:
    Uses legitimate system sources (e.g., `VSS`, `ESENT`) for Event Log injection to bypass source-based filtering.
    ```bash
    python scripts/unified_implant.py --discrete
    ```

2.  **Fast Mode**:
    Disables sleep delays for rapid artifact generation (useful for testing/demos).
    ```bash
    python scripts/unified_implant.py --fast --discrete
    ```

3.  **Test Mode**:
    Runs a single iteration to verify model loading and pipeline integrity.
    ```bash
    python scripts/unified_implant.py --test
    ```

---

## 6. Verification

How to verify that the implant is working correctly.

### A. Event Logs
1.  Open **Event Viewer** (`eventvwr.msc`).
2.  Navigate to **Windows Logs** -> **Application**.
3.  Look for events from sources like `VSS`, `ESENT`, or `Software Protection Platform Service`.
4.  Verify the content matches the "AI PREDICTION" output in the console.

### B. Browser History
1.  Open **Chrome** or **Edge**.
2.  Press `Ctrl+H` to open History.
3.  Verify that new entries (e.g., `github.com`, `stackoverflow.com`) appear with recent timestamps.

### C. DNS Cache
1.  Open a Command Prompt.
2.  Run:
    ```cmd
    ipconfig /displaydns
    ```
3.  Verify that domains generated by the implant are present in the cache.

---

## Troubleshooting

-   **"Write-EventLog" Errors**: Ensure you are running as **Administrator**. If using `--discrete`, ensure the source exists (the script attempts to harvest valid ones).
-   **Browser DB Locked**: If Chrome/Edge is open, the script may fail to inject history. This is normal behavior (handled by try-catch). Close the browser to allow injection.
-   **Model Load Failed**: Ensure the checkpoints exist in `checkpoints/host_model` and `checkpoints/network_model`. If not, run the training steps again.
